import Embeddingtools as ebt
import numpy as np
import math

#Qsort for float number
def partition(list1,list2, beg, end):
    pivot = list1[end-1]
    i = beg - 1
    for j in range(beg, end-1):
        if list1[j] <= pivot:
            i = i + 1                                 #no ++ or -- operator in python
            list1[i], list1[j] = list1[j], list1[i]       #swap lsit[i],list[j]
            list2[i], list2[j] = list2[j], list2[i]
    list1[i+1], list1[end-1] = list1[end-1], list1[i+1]   #swap list[i+1],list[end-1]
    list2[i+1], list2[end-1] = list2[end-1], list2[i+1]
    return i + 1
 
def sort(listx, listy, beg, end):
    if beg < end - 1:
        q = partition(listx, listy, beg, end)
        sort(listx, listy, beg, q)
        sort(listx, listy, q+1, end)

def sim_py(usr_prfr,embd):
    """
    Calculate the similarity of user preference embedding and embeding matrix
    
    Arguments:
    usr_prfr -- user preference embedding vector, of shape(1, e_dim).
    embd -- phrase embedding vector, of shape(m, e_dim)
    
    Returns:
    sim -- real number, value of the similarity, of shape(m, 1)
    """
    
    sim = (np.linalg.norm(usr_prfr - embd, axis = 1)**2).reshape(-1,1)
    
    return sim


def NDCG_i(preference, selected, candidate_list, w2v, top_k = 5 ):
    
    """
    Calculate the ndcg performance on the div/test set.
    
    Arguments:
    candidate_list -- the hot phrase pool, a list contains 50 hot phrases ['phrase1','phrase2',...,'phrase50']
    selected -- the list of words that has been picked out, variable lenth list of strings
    preference -- the preference vector that is generated by the network, 1d array of shape(e_dim,)
    
    Returns:
    ndcg_i -- the ndcg score of ith sample, sacler
    
    """
    
    #top_k = 5 # hypter parameter that we could change
    
    embedding_list = []
    
    for phrase in candidate_list:
        oned_arr = ebt.phrase_embedding(phrase,w2v,top_k).reshape(-1,)
        embedding_list.append(oned_arr) #Here the phrase embedding is a list of 1d array.
        
    embedding_arr = np.array(embedding_list)
    sim_arr = sim_py(preference.reshape(1,-1),embedding_arr)
    #Here I created the inverse sim arr, inorder to obtain the index for reverse sort
    inverse_sim_arr = 1/sim_arr
    #Then we obtain the phrase that has been sorted
    
    list_inv_sim = list(inverse_sim_arr.reshape(-1,))
    sort(list_inv_sim, candidate_list, 0, len(list_inv_sim))
    phrase_sorted = candidate_list
    #Here we obtain the phrase list in the new state
    
    
    #print(phrase_sorted)
    #print(selected)
    #Check our rank and the user preference
    
    click = []
    for i in selected:
        click.append(phrase_sorted.index(i))
    #Then we obtained all the index of user clicks
    
    rel = []
    click_efficiency = len(click)
    for i in range(len(candidate_list)):
        if i in set(click):
            rel.append(2**click_efficiency-1)
            click_efficiency -= 1
        else:
            rel.append(0)
    #This is the relation of the user clicks
    
    DCG = 0
    for i in range(len(candidate_list)):
        #print(math.log(i+1+1,2))
        DCG += rel[i]/math.log(i+1+1,2)
    #Then we have the value of DCG
    
    IDCG = 0
    for j in range(len(candidate_list)):
        if j <= len(click)-1:
            IDCG += (2**(j+1)-1)/math.log(j+1+1,2)
        else:
            IDCG += 0

    NDCG = DCG / IDCG
    print('NDCG = {}'.format(NDCG))
    
    return NDCG

def NDCG_all(predictions, tuple_list, w2v, top_k = 5):
    """
    Here we want to calculate the total NDCG score of a test set.
    
    Arguments:
    predictions -- the np.array of preference predictions of shape(m,n_dim)
    tuple_list -- the list of all the (selected, candidate_list) tuple. 
                detailed data structure has been claimed in the testing_set_constructor function
    
    Returns:
    NDCG_ave -- the average NDCG of all the dev/test sample
    
    """
    NDCG_ave = 0
    for i in range(len(tuple_list)):
        NDCG_ave += NDCG_i(predictions[i],tuple_list[i][0],tuple_list[i][1], w2v, top_k)
    
    NDCG_ave /= len(tuple_list)
    
    return NDCG_ave

def top_6_coverage_i(preference, recommend_list, candidate_list, w2v, top_k = 5):
    '''
    This is a function used to evaluate the top 6 coverage of the new recommender. 
    We simply use it to see the how does the new system different from the old one.

    Arguments:
    preference -- the preference vector that is generated by the network, 1d array of shape(e_dim,)
    recommend_list -- the recommend list [recommend1, recommend2, ..., recommend_{negative_samples}]
    candidate_list -- the hot phrase pool, a list contains 50 hot phrases ['phrase1','phrase2',...,'phrase50']

    Returns:
    coverage_percent -- the coverage_percent of ith sample, sacler
    '''

    embedding_list = []
    #candidate_list = candidate_list[1]
    for phrase in candidate_list:
        oned_arr = ebt.phrase_embedding(phrase,w2v,top_k).reshape(-1,)
        embedding_list.append(oned_arr) #Here the phrase embedding is a list of 1d array.
        
    embedding_arr = np.array(embedding_list)
    sim_arr = sim_py(preference.reshape(1,-1),embedding_arr)
    
    #Here I created the inverse sim arr, inorder to obtain the index for reverse sort
    inverse_sim_arr = 1/sim_arr
    
    #Then we obtain the phrase that has been sorted
    list_inv_sim = list(inverse_sim_arr.reshape(-1,))
    sort(list_inv_sim, candidate_list, 0, len(list_inv_sim))
    phrase_sorted = candidate_list
    
    new_rcmd = phrase_sorted[:len(recommend_list)]
    
    coverage_percent = len(set(new_rcmd) & set(recommend_list)) / len(set(recommend_list))

    return coverage_percent

def top_6_coverage_all(predictions, recommend_list, tuple_list, w2v, top_k = 5):
    """
    Here we want to calculate the total recommend coverage percent of a test set.
    
    Arguments:
    predictions -- the np.array of preference predictions of shape(m,n_dim)
    recommend_list -- the list of all the recommend tuples [recommend1, recommend2, ..., recommend_{negative_samples}]
    tuple_list -- the list of all the (selected, candidate_list) tuple. 
                detailed data structure has been claimed in the testing_set_constructor function
    
    Returns:
    coverage_ave -- the average coverage of all the dev/test sample
    """
    coverage_ave = 0
    for i in range(len(tuple_list)):
        candidate_list = tuple_list[i][1]
        coverage_ave += top_6_coverage_i(predictions[i], recommend_list[i], candidate_list, w2v, top_k)

    coverage_ave /= len(tuple_list)
    
    return coverage_ave