import Embeddingtools as ebt
import numpy as np
import math

#Qsort for float number
def partition(list1,list2, beg, end):
    pivot = list1[end-1]
    i = beg - 1
    for j in range(beg, end-1):
        if list1[j] <= pivot:
            i = i + 1                                 #no ++ or -- operator in python
            list1[i], list1[j] = list1[j], list1[i]       #swap lsit[i],list[j]
            list2[i], list2[j] = list2[j], list2[i]
    list1[i+1], list1[end-1] = list1[end-1], list1[i+1]   #swap list[i+1],list[end-1]
    list2[i+1], list2[end-1] = list2[end-1], list2[i+1]
    return i + 1
 
def sort(listx, listy, beg, end):
    if beg < end - 1:
        q = partition(listx, listy, beg, end)
        sort(listx, listy, beg, q)
        sort(listx, listy, q+1, end)

def sim_py(usr_prfr,embd):
    """
    Calculate the similarity of user preference embedding and embeding matrix
    
    Arguments:
    usr_prfr -- user preference embedding vector, of shape(1, e_dim).
    embd -- phrase embedding vector, of shape(m, e_dim)
    
    Returns:
    sim -- real number, value of the similarity, of shape(m, 1)
    """
    
    #norm
    usr_norm = np.linalg.norm(usr_prfr)
    #print(usr_norm)
    ebd_norm = np.linalg.norm(embd, axis = 1).reshape(-1,1)
    #print(ebd_norm)
    
    #inner_product
    inner_product = np.dot(embd,usr_prfr.T)
    #print(inner_product)
    
    #similarity
    sim = inner_product/(usr_norm*ebd_norm)
    
    return sim


def NDCG_i(candidate_list, selected, preference, w2v):
    
    """
    Calculate the ndcg performance on the div/test set.
    
    Arguments:
    candidate_list -- the hot phrase pool, a list contains 50 hot phrases.
    selected -- the list of words that has been picked out, variable lenth list of strings
    preference -- the preference vector that is generated by the network, 1d array of shape(e_dim,)
    
    Returns:
    ndcg_i -- the ndcg score of ith sample, sacler
    
    """
    
    top_k = 5 # hypter parameter that we could change
    
    embedding_list = []
    
    for phrase in candidate_list:
        oned_arr = ebt.phrase_embedding(phrase,w2v,top_k).reshape(-1,)
        embedding_list.append(oned_arr) #Here the phrase embedding is a list of 1d array.
        
    embedding_arr = np.array(embedding_list)
    sim_arr = sim_py(preference.reshape(1,-1),embedding_arr)
    #Here I created the inverse sim arr, inorder to obtain the index for reverse sort
    inverse_sim_arr = 1/sim_arr
    #Then we obtain the phrase that has been sorted
    
    list_inv_sim = list(inverse_sim_arr.reshape(-1,))
    sort(list_inv_sim, candidate_list, 0, len(list_inv_sim))
    phrase_sorted = candidate_list
    #Here we obtain the phrase list in the new state
    
    
    print(phrase_sorted)
    print(selected)
    #Check our rank and the user preference
    
    click = []
    for i in selected:
        click.append(phrase_sorted.index(i))
    #Then we obtained all the index of user clicks
    
    rel = []
    click_efficiency = len(click)
    for i in range(len(candidate_list)):
        if i in set(click):
            rel.append(2**click_efficiency-1)
            click_efficiency -= 1
        else:
            rel.append(0)
    #This is the relation of the user clicks
    
    DCG = 0
    for i in range(len(candidate_list)):
        #print(math.log(i+1+1,2))
        DCG += rel[i]/math.log(i+1+1,2)
    #Then we have the value of DCG
    
    IDCG = 0
    for j in range(len(candidate_list)):
        if j <= len(click)-1:
            IDCG += (2**(j+1)-1)/math.log(j+1+1,2)
        else:
            IDCG += 0

    NDCG = DCG / IDCG
    print('NDCG = {}'.format(NDCG))
    
    return NDCG

def NDCG_all(predictions, tuple_list, w2v):
    """
    Here we want to calculate the total NDCG score of a test set.
    
    Argument:
    predictions -- the np.array of preference predictions of shape(m,n_dim)
    tuple_list -- the list of all the (candidate_list, selected, preference) tuple. 
                detailed data structure has been claimed in the NDCG_i function
    
    Return:
    NDCG_ave -- the average NDCG of all the dev/test sample
    
    """
    NDCG_ave = 0
    for i in range(len(tuple_list)):
        NDCG_ave += NDCG_i(predictions[i],tuple_list[0],tuple_list[1], w2v)
    
    NDCG_ave /= len(tuple_list)
    
    return NDCG_ave

def top_6_coverage(candidate_list, box_word, ):
    pass